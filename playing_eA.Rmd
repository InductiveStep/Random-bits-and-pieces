---
title: "Comparing {_eefAnalytics_} and {_lmeInfo_}"
author: "Andi Fugard ([@andi@sciences.social](https://sciences.social/@andi))"
date: "Last knitted `r format(Sys.Date(), '%d %B %Y')`"
output:
  html_notebook:
    code_folding: none
  html_document:
    df_print: paged
---


In multilevel analyses, it is often necessary to estimate a standardised mean difference (SMD) such that the numerator mean effect comes from a different model than the denominator SD. The numerator could be a covariate-adjusted mean difference and the denominator the SD from the sum of residual and random effect variances in a model without covariate adjustment. For example,  [statistical analysis guidance for EEF evaluations](https://educationendowmentfoundation.org.uk/projects-and-evaluation/evaluation/evaluation-guidance-and-resources/evaluation-design) requires this approach alongside confidence intervals.

This note simulates data with known sample effect size, covariate-outcome association, and random effect variances, and estimates the SMD using the two packages in R I know that directly offer the calculation:

1. {_eefAnalytics_} has a function _crtFREQ_ that wraps up calls to _lme4::lmer_ and does the sums for total and residual variance, with and without covariate adjustment.
2. {_lmeInfo_} has a function _g_mlm_ that takes two _nlme::lme_ models and allows you to select which fixed and random effect variance estimates go into the ratio.

Surprisingly, {_eefAnalytics_} does not follow EEF guidance. I can, however, replicate what it does using {_lmeInfo_}. Also I can get {_lmeInfo_} to provide the answer I expect.

(I'm aware of arguments against SMDs, e.g., Tukey, 1969, and arguments for using an SD from a survey of the population of interest.)


## Include required libraries

```{r}
quiet_library <- \(...) library(...) |> suppressPackageStartupMessages()

quiet_library(tidyverse)
quiet_library(lme4)
quiet_library(tictoc)
quiet_library(beepr)
quiet_library(lmeInfo)
quiet_library(eefAnalytics)
quiet_library(nlme)
quiet_library(lmeInfo)
```


## Parameters for the simulation

```{r}
n_schools  <- 1000
n_pupils   <- 100
n_total    <- n_schools * n_pupils
n_treat    <- n_total / 2
cov_var    <- 0.6  # proportion of variance explained by the pupil covariate
school_var <- 0.3  # proportion of variance explained by school
es         <- 1.23 # the effect size we want to simulate

stopifnot(n_total %% 2 == 0)
stopifnot(n_schools %% 2 == 0)
```


The effect size we're looking for is `r es`.


## Simulate the data

Note that I'm trying to get the sample to have exactly the properties I want, hence all the scaling to get sample SD = 1 and use of residuals to remove sample correlations.

```{r}
set.seed(42)
my_scale <- function(...) scale(...) |> as.numeric()
school_sim <- tibble(school       = 1:n_schools,
                     noise_school = rnorm(n_schools))

sim_dat <- tibble(
  id         = 1:n_total,
  school      = rep(1:n_schools, n_pupils) |> sort(),
  treat       = (school <= n_schools / 2) + 0,
  noise0      = rnorm(n_total)
) |>
  left_join(school_sim, by = "school") |>
  mutate(
    ranef_school = my_scale(lm(noise_school ~ treat)$resid) * sqrt(school_var),
    noise1       = lm(rnorm(n_total) ~ ranef_school + factor(school))$resid |>
                     my_scale(),
    noise2       = lm(noise0 ~ noise1 + ranef_school + factor(school))$resid |>
                     my_scale(),
    resid        = noise1 * sqrt(1 - cov_var - school_var),
    covar        = noise2 * sqrt(cov_var),
    y            = resid + ranef_school + covar + es * treat
  )
```


## Descriptives

```{r}
sim_dat |>
  select(-starts_with("noise")) |>
  pivot_longer(cols = everything()) |>
  filter(!name %in% c("id", "school")) |>
  group_by(name) |>
  summarise(
    mean = mean(value),
    sd = sd(value),
    var = sd^2,
    min = min(value),
    max = max(value)
  ) |>
  mutate(across(where(is.numeric), \(x) round(x, 2)))
```


The SD for y is over 1 since it's a mixture of normals. We can get (nearly) 1 by calculating the SD by group and pooling:


```{r}
by_group_summary <- sim_dat |>
  group_by(treat) |>
  summarise(mean_y = mean(y), sd_y = sd(y))
by_group_summary |> round(3)
```


```{r}
by_group_summary$sd_y^2 |> mean() |> sqrt()
```

Here are the covariances:

```{r}
sim_dat |>
  select(-starts_with("noise")) |>
  select(-c("id", "school")) |>
  cov() |>
  round(2) |>
  as.data.frame()
```

## {_eefAnalytics_}

(In case you too try this approach, _crtFREQ_ wants the random effect ID to be a numeric and doesn't like factors.)

This first example includes only treatment group and random effect, with no covariate. It should provide the correct answer, though this isn't generally a good idea as the CI will be too wide:

```{r}
eefa_uncond <- crtFREQ(
  y ~ treat,
  random = "school",
  intervention = "treat",
  data = sim_dat
)
eefa_uncond
```

```{r}
should_be_correct <- eefa_uncond$ES$treat1["Total",]$Estimate
stopifnot(round(should_be_correct, 2) == round(es, 2))
```

As expected, the conditional effect size using the total variance is `r should_be_correct`, matching the target (`r es`).

The following call with the covariate included yields too large an answer for the conditional total and too small an answer for the unconditional total effect:

```{r}
eef_wrong <- crtFREQ(
  y ~ treat + covar,
  random = "school",
  intervention = "treat",
  data = sim_dat
)
eef_wrong
```

```{r}
too_big_es   <- eef_wrong$ES$treat1["Total",]$Estimate
too_small_es <- eef_wrong$Unconditional$ES$treat1["Total",]$Estimate
stopifnot(too_big_es > es)
stopifnot(too_small_es < es)
```


We're aiming for `r es`. The total conditional effect size is `r too_big_es` and the unconditional is `r too_small_es`.



## {_lmeInfo_}

Let's see if {_lmeInfo_} does better. First fit a model for the numerator (effect estimate) and denominator (SD). I've also fitted an intercept-only model, for use later.

```{r}
lme_num <- lme(
  fixed = y ~ treat + covar,
  random = ~ 1 | school,
  data = sim_dat,
  method = "REML",
  control = lmeControl(opt = "optim")
)

lme_den <- lme(
  fixed = y ~ treat,
  random = ~ 1 | school,
  data = sim_dat,
  method = "REML",
  control = lmeControl(opt = "optim")
)

lme_empty <- lme(
  fixed = y ~ 1,
  random = ~ 1 | school,
  data = sim_dat,
  method = "REML",
  control = lmeControl(opt = "optim")
)
```


```{r}
correct_es_est <- g_mlm(
  lme_num,
  p_const = c(0,1,0),
  mod_denom = lme_den,
  r_const = c(1,1),
  infotype = "expected",
  separate_variances = FALSE
)
correct_es_est
```

```{r}
stopifnot(round(correct_es_est$g_AB, 2) == es)
```

The estimate is as desired, to two decimal places. In full: 

```{r}
correct_es_est$g_AB
```

We can also get a CI:

```{r}
CI_g(correct_es_est) |> round(2)
```


## Replicating {_eefAnalytics_} using {_lmeInfo_}

Let's see if we can replicate {_eefAnalytics_}. Here's the conditional effect size:

```{r}
conditional_eef_style <- g_mlm(
  lme_num,
  p_const = c(0,1,0),
  mod_denom = lme_num,
  r_const = c(1,1),
  infotype = "expected",
  separate_variances = FALSE
)
conditional_eef_style
```

```{r}
stopifnot(round(conditional_eef_style$delta_AB, 2) == round(too_big_es, 2))
```


`r conditional_eef_style$delta_AB` matches {_eefAnalytics_}'s `r too_big_es` to two decimal places.

And the unconditional effect size:

```{r}
unconditional_eef_style <- g_mlm(
  lme_num,
  p_const = c(0,1,0),
  mod_denom = lme_empty,
  r_const = c(1,1),
  infotype = "expected",
  separate_variances = FALSE
)
unconditional_eef_style
```

```{r}
stopifnot(round(unconditional_eef_style$g_AB, 2) == round(too_small_es, 2))
```


`r unconditional_eef_style$g_AB` again matches {_eefAnalytics_}'s `r too_small_es` to two decimal places.


The CIs:

```{r}
CI_g(conditional_eef_style) |> round(2)
CI_g(unconditional_eef_style) |> round(2)
```

The CI matches for the conditional total but not the unconditional total. Here are the corresponding estimates again from {_eefAnalytics_}:

```{r}
eef_wrong$ES$treat1["Total", c("95% LB", "95% UB")]
```

```{r}
eef_wrong$Unconditional$ES$treat1["Total", c("95% LB", "95% UB")]
```


