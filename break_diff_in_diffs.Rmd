---
title: "A contrived example to break diff-in-diffs"
author: "Andi Fugard"
date: "28 December 2024"
output:
  html_document:
    df_print: paged
---


Include packages:

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(did)
library(WeightIt)
library(MatchIt)
library(cobalt)
library(marginaleffects)
```



First setup the true scores for each individual:

```{r}
set.seed(42)
true_outcomes <- data.frame(id = 1:8000) |>
  mutate(true = rnorm(n(), 0, 1))
```

Look at a random sample:

```{r}
true_outcomes |>
  mutate(true = round(true, 2)) |>
  slice_sample(n = 10)
```


Now the measured outcomes, which are noisy versions of the true score:

```{r}
gen_obs <- function(id, true, sd, n) {
  data.frame(time = 1:n) |>
    mutate(id = id, .before = time) |>
    mutate(true = true,
           y = true + rnorm(n, 0, sd))
}

sim_dat <- pmap_df(true_outcomes,
                   \(id, true) gen_obs(id = id, true = true, sd = 1, n = 4)) |>
  mutate(y = scale(y) |> as.numeric())
```

Look at a random sample:

```{r}
sim_dat |>
  mutate(true = round(true, 2),
         y = round(y, 2)) |>
  slice_sample(n = 10)
```

We have standardised y:

```{r}
mean(sim_dat$y) |> round(2)
sd(sim_dat$y) |> round(2)
```

The correlations:

```{r}
sim_dat |>
  pivot_wider(names_from = time, values_from = y) |>
  select(-id) |>
  cor() |>
  round(1)
```

Each measurement is correlated about .7 with the (unmeasurable) true score and the measurements are correlated around .5 with each other. From here on, we will ignore the true scores and only use measurements.

Next, select people for the intervention if their scores are 1 SD more more below the population mean for all periods prior to the intervention period.

```{r}
ids <- list()

ids[[3]] <- sim_dat |>
  filter(time %in% 1:2 & y < -1) |>
  pull(id) |>
  unique() |>
  sample(size = 500)

ids[[4]] <- sim_dat |>
  filter(time %in% 1:3 & y < -1) |>
  pull(id) |>
  setdiff(ids[[3]]) |>
  unique() |>
  sample(size = 500)

ids[[5]] <- setdiff(sim_dat$id, c(ids[[3]], ids[[4]])) |>
  sample(size = 500)
```

Build a dataset mapping ID to group. {did} treats group = 0 as never-treated.

```{r}
group_ids <- list(
  data.frame(id = ids[[3]], group = 3),
  data.frame(id = ids[[4]], group = 4),
  data.frame(id = ids[[5]], group = 0)) |>
  bind_rows()
stopifnot((group_ids |> duplicated() |> sum()) == 0)
```

Join onto the main dataset and drop missings:

```{r}
sim_dat <- sim_dat |>
  left_join(group_ids) |>
  na.omit()
```

Here are the means by group and when each group receives the intervention.

```{r rows.print = 20}
sim_dat |>
  group_by(group, time) |>
  summarise(mean_y = mean(y) |> round(1),
            n = n()) |>
  mutate(treat = time >= group & group != 0, .after = time)
```


A couple of plots:

```{r warning=FALSE}
curvy_plot <- sim_dat |>
  mutate(group = factor(group)) |>
  ggplot() +
  aes(x = time, y = y, colour = group) +
  geom_smooth(method = "loess", formula = y ~ x)
curvy_plot + 
  geom_jitter(alpha = .5, width = .1, size = .1)
```

Zoom in and remove the points:

```{r warning=FALSE}
curvy_plot
```

The never treated group (0) cruise along a little above the population mean (0 by design) with no apparent change. The means of group 3 and 4 are much lower (as expected, since we select them to be 1 SD below the mean or less), apparently increasing as the intervention is introduced.


Let's see what {did} makes of this:

```{r}
did_mod <- att_gt(
  yname = "y",
  gname = "group",
  control_group = "notyettreated",
  idname = "id",
  tname = "time",
  data = sim_dat,
  est_method = "reg",
  base_period = "varying"
)
did_mod
```


```{r}
did_mod |>
  ggdid()
```


```{r}
did_mod |>
aggte(type = "group") |>
  ggdid()
```



```{r}
did_mod |>
  aggte(type = "dynamic") |>
  ggdid()
```

Would we conclude that the intervention was effective if we didn't know how the data were generated...?


What happens if we remove the never-treated group? We will only be able to test the effect for group 3 (using group 4 in its pre-intervention phase as control).


```{r}
sim_dat_sometimes_treated <- sim_dat |>
  filter(group != 0)
```


```{r message=FALSE, warning=FALSE}
sim_dat_sometimes_treated |>
  mutate(group = factor(group)) |>
  ggplot() +
  aes(x = time, y = y, colour = group) +
  geom_smooth(method = "loess", formula = y ~ x)
```


```{r}
did_mod_2 <- att_gt(
  yname = "y",
  gname = "group",
  control_group = "notyettreated",
  idname = "id",
  tname = "time",
  data = sim_dat_sometimes_treated,
  est_method = "reg",
  base_period = "varying"
)

did_mod_2
```


```{r}
did_mod_2 |>
  ggdid()
```

Same issue.

### Alternatives to DID

First setup wide datasets, separately for groups 3 and 4. These have data for one time point (immediate outcomes) and the previous time point measure of the outcome as baseline. 

```{r}
get_wide <- function(.data, selected_group) {
  res <-  .data |>
    filter(time %in% c(selected_group - 1, selected_group)) |>
    filter(group == 0 | group == selected_group | group > selected_group) |>
    mutate(treat = as.numeric(group == selected_group),
           pre_post = ifelse(time == selected_group, "outcome", "baseline")) |>
    select(-c(time, true)) |>
    pivot_wider(names_from = pre_post, values_from = y)
  
  res
}
```

```{r}
wide_3 <- sim_dat |>
  get_wide(3)
wide_4 <- sim_dat |>
  get_wide(4)
```

```{r}
descript <- function(.data) {
  .data |>
    group_by(group, treat) |>
    summarise(baseline = mean(baseline),
              outcome = mean(outcome)) |>
    arrange(treat)
}  
```


```{r}
wide_3 |>
  descript()
```


```{r}
wide_4 |>
  descript()
```

A simple regression model works fine for group 3 (finding the null result):

```{r}
lm_mod_3 <- lm(outcome ~ baseline + treat, data = wide_3)
summary(lm_mod_3)
```

It doesn't for group 4, presumably because we are selecting people based on the previous three observations, so the single baseline isn't good enough:

```{r}
lm_mod_4 <- lm(outcome ~ baseline + treat, data = wide_4)
summary(lm_mod_4)
```


Try entropy balancing...

```{r}
ebal_3 <- weightit(treat ~ baseline,
                  data = wide_3, estimand = "ATT", method = "ebal")
bal.tab(ebal_3, stats = c("m", "v"), thresholds = c(m = .1)) 
```

```{r}
bal.plot(ebal_3, var.name = "baseline", which = "both")
```

```{r}
ebal_4 <- weightit(treat ~ baseline,
                  data = wide_4, estimand = "ATT", method = "ebal")
```


```{r}
summary(ebal_4)
```


```{r}
bal.tab(ebal_4, stats = c("m", "v"), thresholds = c(m = .1)) 
```


```{r}
bal.plot(ebal_4, var.name = "baseline", which = "both")
```



```{r}
ebal_fit_3 <- lm_weightit(outcome ~ treat * baseline,
                          data = wide_3,
                          weightit = ebal_3)
avg_comparisons(ebal_fit_3,
                variables = "treat",
                newdata = subset(wide_3, treat == 1) |> select(-group))
```

Fine, though could be closer to zero...


```{r}
bal.plot(ebal_4, "baseline")
```


```{r}
ebal_fit_4 <- lm_weightit(outcome ~ treat * baseline,
                          data = wide_4,
                          weightit = ebal_4)
avg_comparisons(ebal_fit_4,
                variables = "treat",
                newdata = subset(wide_4, treat == 1) |> select(-group))
```

And, nope. Still shows an effect for group 4.

What if we weight on the previous three time points...?


```{r}
more_baseline_4 <- sim_dat |>
  filter(time %in% 1:4) |>
  filter(group == 0 | group == 4) |>
  mutate(treat = as.numeric(group == 4)) |>
  select(-c(true)) |>
  pivot_wider(names_from = time, values_from = y) |>
  rename(outcome = `4`,
         x1 = `1`,
         x2 = `2`,
         x3 = `3`)

stopifnot(mean(more_baseline_4$outcome) == mean(wide_4$outcome))

more_baseline_4 |> head()
```



```{r}
loads_dat_ebal_4 <- weightit(treat ~ x1 + x2 + x3,
                  data = more_baseline_4, estimand = "ATT", method = "ebal")
bal.tab(loads_dat_ebal_4, stats = c("m", "v"), thresholds = c(m = .1)) 
```

```{r}
loads_dat_ebal_4_fit <- lm_weightit(outcome ~ treat * (x1 + x2 + x3),
                          data = more_baseline_4,
                          weightit = loads_dat_ebal_4)
avg_comparisons(loads_dat_ebal_4_fit,
                variables = "treat",
                newdata = subset(more_baseline_4, treat == 1) |> select(-group))
```

It's heading the right direction...

Wonder what a simple regression will do:

```{r}
simple_ols <- lm(outcome ~ treat + x1 + x2 + x3,
                 data = more_baseline_4)
summary(simple_ols)
```

Slightly better.

Finally, try matching:

```{r}
match_the_thing <- matchit(
  treat ~ x1 + x2 + x3,
  method = "nearest",
  distance =  "glm",
  caliper = .01,
  data = more_baseline_4,
  replace = TRUE
)
bal.tab(match_the_thing, stats = c("m", "v"), thresholds = c(m = .1)) 
```

```{r}
match_dat <- get_matches(match_the_thing, id = "id_match") |>
  select(-group)
match_dat |> head()
```


```{r}
matched_lm <- lm(outcome ~ treat * (x1 + x2 + x3),
                 data = match_dat,
                 weights = weights)
avg_comparisons(matched_lm, variables = "treat",
                vcov = ~ subclass + id,
                newdata = subset(treat == 1))
```

